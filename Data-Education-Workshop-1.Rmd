---
title: "Data Education Workshop 1"
subtitle: "Copyright 2021 Lara Rostomian All Rights Reserved"
output: 
  html_document:
    toc: true 
    toc_depth: 3
---

## Introduction

The Center for Systems Science and Engineering at Johns Hopkins was among the earliest to collect and publish global data related to the COVID-19 pandemic. The data used for their [reporting dashboard](https://coronavirus.jhu.edu/map.html), aggregated from multiple sources and updated daily, is freely available on [Github](https://github.com/CSSEGISandData/COVID-19). 

We will review a basic overview of the following steps in data analysis: 

1. Data Import and Cleaning \  
2. Exploratory Data Analysis & Visualization \    
3. Predictive Modeling: Regression and Classification \  

### Setting Up R:

If you're brand new to R, **welcome** we recommend you check out [RSwirl](https://swirlstats.com/students.html) if you haven't already to learn how to set up R and learn some of the basics! 

1. Create New Project (Via Github Repository) & Establish Working Directory \  
2. Create a File (RMD) \  
3. Load Packages Chunk \  

### Load Packages:

First use install.packages() then library()

```{r}
library(tidyr) # Getting Data in Tidy Format
library(tidyverse) # Holy Grail
library(dplyr) # Holy Grail Pt 2
library(lubridate) # Manipulating Data
library(zoo) # Manipulating Data
library(maps) # Mapping Visualizations  
library(ggplot2) # All Visualizations 
library(ggthemes) # All Visualizations Themes 
library(readxl) # Read in Excel Files 
library(splitstackshape) #Prediction Modeling Functions
library(readxl) #Read In Excel Files 
library(caret) #Confusion Matrix
```

## Data Import and Cleaning

Step 0: Finding Data (Look for CSV Files!) 
Step 1: Read in data for  (Make sure you either use raw data link if available or import your CSV file into the same working directory as your Rmd file.) 
Step 2: View Data & Decide What Needs to be "Cleaned"  
Step 3: Data Cleaning! 

```{r}
#Reading in the case data
cases <- read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv")
head(cases)
#Check First and Last Date 
``` 

Reshape the data to long format, so that instead of having many columns of cases for each date, you have one column that stores the cases and one column that stores the dates. 

```{r}
cases_long <- cases %>% gather(date, cases, '1/22/20':'2/19/21') #Check Latest Date
head(cases_long)
```

Convert the new date column to be a date class instead of a character class. 

```{r}
#Check Class
class(cases_long$date)

cases_long$date <-as.Date(cases_long$date, "%m/%d/%y")

#Re-Check Class
class(cases_long$date)
class(cases_long$cases)
```

This data set keeps track of the number of confirmed cases reported for states, provinces, and other sub-regions within a given country but we just want total country data. This data frame also still includes a bunch of other information we're not interested in (Latitude Longitude Etc...) 

We can create a new data frame with only what we're interested in: country name, date, and the total number of cases in the country on that day. 

We can do this by summing up the cases across all of the states/provinces within each country and date.

```{r}
cases_long_country <- cases_long %>% rename(country ="Country/Region") %>%  group_by(country, date) %>% summarize(cases=sum(cases), .groups = "drop") 
head(cases_long_country)
```

So now we're ready for the fun part!

## Exploratory Data Analysis and Visualizations

Step 1: What do we want to explore? \  
Step 2: Whats the best way to visualize it? \  
Step 3: Repeat Steps 1 and 2 Forever \  

So lets say we want to look at only a few countries first to compare their COVID Cases: Armenia, Azerbaijan, Turkey, Georgia, Russia. 

Perhaps the best way to visualize this is a line plot with cases on the Y axis and date on the X axis. But first, we have to restrict our data to only those countries we're interested in including in our plot.

```{r}
countries = c("Armenia", "Azerbaijan","Turkey","Georgia","Russia")
plot1data <- cases_long_country %>% filter(country %in% countries)
ggplot(plot1data, aes(x=date, y=cases, color=country)) + geom_line() + scale_x_date(date_breaks = "1 month", date_labels = "%b") + labs(x = "Date", y = "Cases", title = "Total Confirmed Cases Over Time") + guides(color = guide_legend(title="Country"))
```

The number of cases varies greatly across these five countries. This stretches out the scale of the y-axis and making it hard to see what’s going on in countries where there are fewer cases. Transforming the data can make it easier to interpret your time series plot. We're going to redo this same plot but use a log scale transformation (with base 10) for the y-axis.

```{r}
countries = c("Armenia", "Azerbaijan","Turkey","Georgia","Russia")
plot1data <- cases_long_country %>% filter(country %in% countries)
ggplot(plot1data, aes(x=date, y=cases, color=country)) + geom_line() + scale_y_log10() + scale_x_date(date_breaks = "1 month", date_labels = "%b") + labs(x = "Date", y = "Cases (Log Scale)", title = "Total Confirmed Cases Over Time (Log Scale)") + guides(color = guide_legend(title="Country"))
```

Many public health professionals have been measuring new confirmed cases over a 7 day period (or "7 Day Rolling Averages").
Lets try to make a new variable that calculates that.We will define the seven-day rolling average of new cases as the average of the new cases reported on a given day, the three days before, and the three days after. It’s a “rolling” average because the window of seven days moves along as you calculate the averages for new dates.

```{r}
cases_long_country <- cases_long_country %>% group_by(country) %>% arrange(date) %>%
mutate(new_cases = cases - lag(cases), new_cases_7dayavg = rollmean(new_cases, k = 7, fill = NA)) %>% ungroup()
view(cases_long_country)
```

Let's Plot It! 

```{r}
ggplot(cases_long_country %>% filter(country %in% countries), aes(x=date, y=new_cases_7dayavg, color=country)) +  geom_line() + scale_x_date(date_breaks = "1 month", date_labels = "%b") + labs(x = "Date", y = "New Cases (7-day Rolling Average)", title = "New Confirmed Cases Over Time") + guides(color = guide_legend(title="Country"))
```

Since these countries all have different population sizes, it might be more informative to look at the new cases per-capita. For this we need to use a different data set available again from the Johns Hopkins [Github] (https://github.com/CSSEGISandData/COVID-19) page. 

```{r}
#Reading in the population data
population_data <- read_csv("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/UID_ISO_FIPS_LookUp_Table.csv")
``` 

Back to data cleaning for a minute here: Ultimately we just want the population information in our original case data set that we've been working with this entire time. So let's try to join both data frames together, but before we do that, lets get rid of everything we don't need from this new population data set. 

First, we create a new data frame that stores only the country-level populations, aka where Province_State is NA. Then we get rid of the columns we don't want and rename everything to look nice and match to our existing data_set. 

```{r}
population_data <- population_data %>% subset(is.na(Province_State)) %>% rename(country="Country_Region", population ="Population") %>% select(country, population)
```

Time to join the two data frames (yay!)

```{r}
finaldata <- left_join(cases_long_country, population_data, by = "country")
```

Now its time to account for population in our data analysis. Let's do this by creating a new variable that calculates the seven-day rolling average of new cases per million.

```{r}
finaldata <- finaldata %>% mutate(rollingavg_per_million = 1e6*new_cases_7dayavg/population)
View(finaldata)
```

Let's Plot It Round 4! 

```{r}
ggplot(finaldata %>% filter(country %in% countries), aes(x=date, y=rollingavg_per_million, color=country)) +  geom_line() + scale_x_date(date_breaks = "1 month", date_labels = "%b") + labs(x = "Date", y = "New Cases Per Million (7-day Rolling Average)", title = "New Cases Per Million Over Time") + guides(color = guide_legend(title="Country"))
```

What are some other cool ways you can visualize in R? 

*Heat Maps!* 

```{r}
# Pull out world map data frame
world_map = map_data("world")
country_key = data.frame(rbind(c("Antigua and Barbuda", "Antigua"), 
                               c("Burma", "Myanmar"), 
                               c("Cabo Verde", "Cape Verde"), 
                               c("Congo (Kinshasa)", 
                                 "Democratic Republic of the Congo"), 
                               c("Congo (Brazzaville)", 
                                 "Republic of Congo"), 
                               c("Cote d'Ivoire", "Ivory Coast"), 
                               c("Czechia", "Czech Republic"), 
                               c("Eswatini", "Swaziland"), 
                               c("Holy See", "Vatican"), 
                               c("Korea, South", "South Korea"), 
                               c("North Macedonia", "Macedonia"), 
                               c("Saint Kitts and Nevis", "Saint     Kitts"), 
                               c("Saint Vincent and the Grenadines", 
                                 "Saint Vincent"), 
                               c("Taiwan*", "Taiwan"), 
                               c("Trinidad and Tobago", "Trinidad"), 
                               c("United Kingdom", "UK"), 
                               c("US", "USA")))
names(country_key) = c("JHU", "map")

# Create named vector for recoding country names
recode_map = country_key$JHU; names(recode_map) = country_key$map

# Recode country names in world map data to match with Johns Hopkins
world_map = world_map %>% mutate(region=recode(region, !!!recode_map))

# Only three countries in finaldata don't match with anything in world_map
setdiff(finaldata$country, world_map$region)

# Filter finaldata for a specific data and join with world map data! (Choose a Date) 
finaldata_map = finaldata %>% filter(date==date("2021-1-01")) %>% left_join(world_map, by=c("country"="region"))
```

*Heatmap of Cases Per Million on October 18, 2020*

```{r}
ggplot(finaldata_map, aes(x = long, y = lat, group = group)) + geom_polygon(aes(fill=rollingavg_per_million), color = "white") + 
  theme(panel.grid.major = element_blank(), 
            panel.background = element_blank(),
            axis.title = element_blank(), 
            axis.text = element_blank(),
            axis.ticks = element_blank()) + 
  scale_fill_viridis_c(name = "New cases/mill \n(7-day avg)", 
                       option = "inferno", 
                       trans = "log10") + 
  labs(title = "New confirmed cases per million on DATE")  #Update Date for Title
```

### More COVID-19 Resources
*WHO ShinyApp*: [ShinyApp](https://worldhealthorg.shinyapps.io/covid/)

*More Resources:* [Top 100 R resources on Novel COVID-19 Coronavirus](https://statsandr.com/blog/top-r-resources-on-covid-19-coronavirus/)


## Predecitive Modeling: Regression & Classification 

*Predictive modeling* is the problem of developing a model using historical data to make a prediction on new data where we do not have the answer. Predictive modeling can be described as the mathematical problem of approximating a mapping function (f) from input variables (X) to output variables (y). *Classification Predictive Modeling* is the task of approximating a mapping function (f) from input variables (X) to discrete output variables (y). The output variables are often called labels or categories, for this we use *Logistic Regression* methods. The mapping function predicts the class or category for a given observation. *Regression Predictive Modeling* is the task of approximating a mapping function (f) from input variables (X) to a continuous output variable (y). A continuous output variable is a real-value, such as an integer or floating point value. These are often quantities, such as amounts and sizes, for this we use *Linear Regression*.

*Information Source:* [Difference Between Classification and Regression in Machine Learning](https://machinelearningmastery.com/classification-versus-regression-in-machine-learning/#:~:text=There%20is%20an%20important%20difference,is%20about%20predicting%20a%20quantity.&text=That%20regression%20is%20the%20problem,quantity%20output%20for%20an%20example.). 

## Logistic Regression:

### Diabetes:
*Data Source:* [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php) 
We will be using the features available in this dataset to predict diabetes diagnosis [**Classification** aka **Logistic Regression**!]

```{r}
diabetes <- read.csv(file="diabetes_data_upload.csv")
head(diabetes)

#good predictors!
ggplot(diabetes, aes(x=as.factor(class), fill=Polyuria)) + geom_bar()  + xlab("Diabetes Diagnosis") + ylab("Count") + ggtitle("Relationship Between Polyuria and Diabetes Diagnosis")
ggplot(diabetes, aes(x=as.factor(class), fill=Polyphagia)) + geom_bar()  + xlab("Diabetes Diagnosis") + ylab("Count")+ggtitle("Relationship Between Polyphagia and Diabetes Diagnosis")
ggplot(diabetes, aes(x=as.factor(class), fill=Polydipsia)) + geom_bar()  + xlab("Diabetes Diagnosis") + ylab("Count")+ggtitle("Relationship Between Polydipsia and Diabetes Diagnosis")

#not so good predictors!
ggplot(diabetes, aes(x=as.factor(class), fill=Itching)) + geom_bar()  + xlab("Diabetes Diagnosis") + ylab("Count") +ggtitle("Relationship Between Itching and Diabetes Diagnosis")
ggplot(diabetes, aes(x=as.factor(class), fill=delayed.healing)) + geom_bar()  + xlab("Diabetes Diagnosis") + ylab("Count") +ggtitle("Relationship Between Delayed Healing and Diabetes Diagnosis")

diabetes_1 <- diabetes %>% select(-Age,-class,-Gender)
diabetes_1 <- ifelse(diabetes_1 == "Yes", 1, 0)
diabetes_1 <- as.data.frame(diabetes_1)
diabetes_1 <- diabetes_1 %>% mutate(row.names(diabetes))

diabetes_2 <- diabetes %>% select(Age,class,Gender)
diabetes_2 <- as.data.frame(diabetes_2)
diabetes_2$class <- ifelse(diabetes_2$class == "Positive", 1, 0)
diabetes_2$Gender <- ifelse(diabetes_2$Gender == "Male", 1, 0)
diabetes_2 <- diabetes_2 %>% mutate(row.names(diabetes))

total <- merge(diabetes_1, diabetes_2, by="row.names(diabetes)")
total <- total %>% select(-'row.names(diabetes)')
head(total)
```

```{r}
#Set Up Train Set and Test Set
train_set <- total[1:260,]
test_set_0 <- total[260:520,]
test_set <- total[260:520,] %>% select(-class)
new_data <- test_set%>%slice(1:10)

#Create Logistic Model
logistic_model <-glm(class ~ ., family = binomial, train_set)
print(logistic_model)

#Predict Test Set Results
predicted <- predict(logistic_model, type = "response",  newdata = new_data)
predicted.class <- ifelse(predicted > 0.5, 1, 0)
predicted.class <- as.factor(predicted.class)
observed <- test_set_0[1:10,]

#Compare to Actual Observed Results
print(predicted)
print(observed$class)
print(predicted.class)

#Input New Values Into Model (Choose Some Values!)
logistic_model_2 <-glm(class ~ Age + Obesity + Gender + Polyuria + Polydipsia + Polyphagia, family = binomial, train_set)
new_data_2 <- data.frame(Age=40, Obesity = 0, Gender = 1, Polyuria = 0, Polydipsia = 1, Polyphagia = 1)
predicted_2 <- predict(logistic_model_2, newdata = new_data_2, type="response")
predicted.class.2 <- ifelse(predicted_2 > 0.5, 1, 0)

#Prediction of diabetes diagnosis for a  non-obese 40 year old male who has experienced polydispsia and polyphagia but not polyuria.   
print(predicted_2)
print(predicted.class.2)
```
## Linear Regression

### NHANES Study:
The NHANES I Epidemiologic Follow-up Study (NHEFS) is a national longitudinal study designed to investigate the relationships between clinical, nutritional, and behavioral factors assessed in the first National Health and Nutrition Examination Survey NHANES I and subsequent morbidity, mortality, and hospital utilization, as well as changes in risk factors, functional limitation, and institutionalization.

*Data Source:* [CDC: NHANES Study, NHEFS Dataset](https://wwwn.cdc.gov/nchs/nhanes/nhefs/default.aspx/) 
We will be using the features available in this dataset to predict systolic blood pressure (which is a continuous outcome) [**Regression Predictive Modeling** aka **Linear Regression**!]

```{r}
data <- read_excel("nhefs.xlsx")
attach(data)

ggplot(data, aes(x=cholesterol, y=sbp)) + geom_point()  + xlab("Cholesterol") + ylab("Systolic Blood Pressure") + geom_smooth(method=lm) +ggtitle("Relationship Between Cholesterol and SBP")
ggplot(data, aes(x=age, y=sbp)) + geom_point()  + xlab("Age") + ylab("Systolic Blood Pressure") + geom_smooth(method=lm) +ggtitle("Relationship Between Age and SBP")

#Set Up Train Set and Test Set
train_set_2 <- data[1:814,]
test_set_0_2 <- data[814:1629,] %>% filter(!is.na(sbp)) %>%filter(!is.na(age)) %>% filter(!is.na(cholesterol))
test_set_2 <- test_set_0_2 %>% select(-sbp)

linear_model <- lm(sbp ~ age + cholesterol, data = train_set_2)

summary(linear_model)

linear_predicted <- predict(linear_model, newdata = test_set_2)
linear_predicted <- as.data.frame(linear_predicted)

linear_observed <- test_set_0_2 %>% select(sbp)
linear_predicted[1:10,]
linear_observed[1:10,]

new_df <- test_set_0_2 %>% mutate(prediction = linear_predicted)
new_df <- new_df %>% select(sbp, prediction)

#Mean Absolute Error 
((sum(abs(new_df$sbp - new_df$prediction)))/ 772)
#13.71362
```

Lets try to refine our model by adding some more variables...

```{r}
ggplot(data, aes(x=wt82, y=sbp)) + geom_point()  + xlab("Weight") + ylab("Systolic Blood Pressure") + geom_smooth(method=lm) +ggtitle("Relationship Between Weight and SBP")
ggplot(data, aes(x=as.factor(hbp), y=sbp)) + geom_boxplot()  + xlab("High Blood Pressure in 1971") + ylab("SBP in 1982") +ggtitle("Relationship Between HBP in 1971 and SBP in 1982")
ggplot(data, aes(x=as.factor(hbpmed), y=sbp)) + geom_boxplot()  + xlab("High Blood Pressure Meds in 1971") + ylab("SBP in 1982") +ggtitle("Relationship Between Using HBP Meds in 1971 and SBP in 1982")

#Set Up Train Set and Test Set
train_set_2.1 <- data[1:814,]
test_set_0_2.1 <- data[814:1629,] %>% filter(!is.na(sbp)) %>%filter(!is.na(age)) %>% filter(!is.na(sex)) %>% filter(!is.na(race)) %>% filter(!is.na(wt82)) %>% filter(!is.na(hbp)) %>% filter(!is.na(cholesterol)) %>% filter(!is.na(hbpmed))
test_set_0_2.1 <- test_set_0_2.1 %>% filter(hbpmed !=2) %>% filter(hbp !=2)
test_set_2.1 <- test_set_0_2.1 %>% select(-sbp)

linear_model_2 <- lm(sbp ~ age + sex + race + wt82 + cholesterol + as.factor(hbpmed) + as.factor(hbp), data = train_set_2.1)

summary(linear_model_2)

linear_predicted_2 <- predict(linear_model_2, newdata = test_set_2.1)
linear_predicted_2 <- as.data.frame(linear_predicted_2)

new_df_2 <- test_set_0_2.1 %>% mutate(prediction = linear_predicted_2)
new_df_2 <- new_df_2 %>% select(sbp, prediction)

#Mean Absolute Error 
((sum(abs(new_df_2$sbp - new_df_2$prediction)))/ 24)
#12.4005

#Slightly more accurate! 
```
